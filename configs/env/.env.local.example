# LLM Quality Observer - Local environment

APP_ENV=local

OPENAI_MODEL_MAIN="OPENAI_MODEL_MAIN_NAME"
OPENAI_MODEL_JUDGE="gpt-5-mini"

# LLM provider (ì˜ˆ: OpenAI)
LLM_API_BASE_URL=https://api.openai.com/v1
LLM_API_KEY="LLM_API_KEY"

LOG_LEVEL=DEBUG

# Batch Evaluation Scheduler
ENABLE_AUTO_EVALUATION=true
EVALUATION_INTERVAL_MINUTES=60
EVALUATION_BATCH_SIZE=10
EVALUATION_JUDGE_TYPE=rule

# Notification Settings (optional)
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
# DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/YOUR/WEBHOOK/URL
NOTIFICATION_SCORE_THRESHOLD=3
